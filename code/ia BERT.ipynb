{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "443f6e4d",
   "metadata": {},
   "source": [
    "# IA prediction d'humeur BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af1403b",
   "metadata": {},
   "source": [
    "instalation des transdormers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da6a222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.10.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (2026.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: C:\\Users\\flocon\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (5.1.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (4.67.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2026.2.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
      "Requirement already satisfied: shellingham in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from typer-slim->transformers) (8.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: C:\\Users\\flocon\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: C:\\Users\\flocon\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: C:\\Users\\flocon\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install transformers\n",
    "!pip install pandas\n",
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f63d4c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flocon\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a9292c",
   "metadata": {},
   "source": [
    "# 1. Charger les données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7c1ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Données chargées : 1000000 lignes\n",
      "✓ Colonnes : ['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny', 'cool', 'text', 'date']\n",
      "                review_id                 user_id             business_id  \\\n",
      "0  J5Q1gH4ACCj6CtQG7Yom7g  56gL9KEJNHiSDUoyjk2o3Q  8yR12PNSMo6FBYx1u5KPlw   \n",
      "1  HlXP79ecTquSVXmjM10QxQ  bAt9OUFX9ZRgGLCXG22UmA  pBNucviUkNsiqhJv5IFpjg   \n",
      "2  JBBULrjyGx6vHto2osk_CQ  NRHPcLq2vGWqgqwVugSgnQ  8sf9kv6O4GgEb0j1o22N1g   \n",
      "3  U9-43s8YUl6GWBFCpxUGEw  PAxc0qpqt5c2kA0rjDFFAg  XwepyB7KjJ-XGJf0vKc6Vg   \n",
      "4  8T8EGa_4Cj12M6w8vRgUsQ  BqPR1Dp5Rb_QYs9_fz9RiA  prm5wvpp0OHJBlrvTj9uOg   \n",
      "\n",
      "   stars  useful  funny  cool  \\\n",
      "0      2       1      0     0   \n",
      "1      5       0      0     0   \n",
      "2      5       0      0     0   \n",
      "3      4       0      0     0   \n",
      "4      5       0      0     0   \n",
      "\n",
      "                                                text                date  \n",
      "0  Went for lunch and found that my burger was me... 2018-04-04 21:09:53  \n",
      "1  I needed a new tires for my wife's car. They h... 2020-05-24 12:22:14  \n",
      "2  Jim Woltman who works at Goleta Honda is 5 sta... 2019-02-14 03:47:48  \n",
      "3  Been here a few times to get some shrimp.  The... 2013-04-27 01:55:49  \n",
      "4  This is one fantastic place to eat whether you... 2019-05-15 18:29:25  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Chemin relatif vers le fichier\n",
    "file_path = \"../data/yelp_academic_reviews4students.jsonl\"\n",
    "\n",
    "# Méthode 1 : Avec pandas (recommandé)\n",
    "try:\n",
    "    data = pd.read_json(file_path, lines=True)\n",
    "    print(f\"✓ Données chargées : {len(data)} lignes\")\n",
    "    print(f\"✓ Colonnes : {list(data.columns)}\")\n",
    "    print(data.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"✗ Fichier introuvable : {file_path}\")\n",
    "    print(\"Vérifiez que le fichier existe dans le dossier 'data' du répertoire parent\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Erreur : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42093872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def load_yelp_dataset(path):\n",
    "    \"\"\"\n",
    "    Charge le dataset Yelp depuis un fichier JSONL\n",
    "    \"\"\"\n",
    "    # Charger directement avec pandas (beaucoup plus simple et rapide)\n",
    "    data = pd.read_json(path, lines=True)\n",
    "\n",
    "    # Ne garder que les colonnes nécessaires\n",
    "    df = pd.DataFrame({\n",
    "        \"texte\": data[\"text\"],\n",
    "        \"stars\": data[\"stars\"]\n",
    "    })\n",
    "\n",
    "    print(f\"✓ Données chargées : {len(df)} lignes\")\n",
    "    print(f\"✓ Distribution des étoiles :\")\n",
    "    print(df[\"stars\"].value_counts().sort_index())\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c952244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Données chargées : 1000000 lignes\n",
      "✓ Distribution des étoiles :\n",
      "stars\n",
      "1    153057\n",
      "2     77630\n",
      "3     98714\n",
      "4    207953\n",
      "5    462646\n",
      "Name: count, dtype: int64\n",
      "1000000\n",
      "                                               texte  stars\n",
      "0  Went for lunch and found that my burger was me...      2\n",
      "1  I needed a new tires for my wife's car. They h...      5\n",
      "2  Jim Woltman who works at Goleta Honda is 5 sta...      5\n",
      "3  Been here a few times to get some shrimp.  The...      4\n",
      "4  This is one fantastic place to eat whether you...      5\n"
     ]
    }
   ],
   "source": [
    "df = load_yelp_dataset(\"../data/yelp_academic_reviews4students.jsonl\")\n",
    "print(len(df))\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d48ea19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(2000, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0fa8a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stars_to_label(stars):\n",
    "    if stars <= 2:\n",
    "        return 0   # negatif\n",
    "    elif stars == 3:\n",
    "        return 1   # neutre\n",
    "    else:\n",
    "        return 2   # positif\n",
    "\n",
    "df[\"label\"] = df[\"stars\"].apply(stars_to_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaca1fb6",
   "metadata": {},
   "source": [
    "# 2. Train / Test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eedbb83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"texte\"].tolist(),\n",
    "    df[\"label\"].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cbec0c",
   "metadata": {},
   "source": [
    "# 3. Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dff4300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 907.94it/s, Materializing param=bert.pooler.dense.weight]                               \n",
      "\u001b[1mBertForSequenceClassification LOAD REPORT\u001b[0m from: bert-base-uncased\n",
      "Key                                        | Status     | \n",
      "-------------------------------------------+------------+-\n",
      "cls.seq_relationship.weight                | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
      "cls.seq_relationship.bias                  | UNEXPECTED | \n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
      "cls.predictions.bias                       | UNEXPECTED | \n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
      "classifier.weight                          | MISSING    | \n",
      "classifier.bias                            | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=3\n",
    ")\n",
    "\n",
    "def tokenize(texts):\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize(train_texts)\n",
    "test_encodings = tokenize(test_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b643f29",
   "metadata": {},
   "source": [
    "\n",
    "# 4. Dataset PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "349fa64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoodDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "train_dataset = MoodDataset(train_encodings, train_labels)\n",
    "test_dataset = MoodDataset(test_encodings, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce8c43",
   "metadata": {},
   "source": [
    "# 5. Modèle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0f4d7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 197/197 [00:00<00:00, 906.89it/s, Materializing param=roberta.encoder.layer.11.output.dense.weight]              \n",
      "\u001b[1mCamembertForSequenceClassification LOAD REPORT\u001b[0m from: camembert-base\n",
      "Key                         | Status     | \n",
      "----------------------------+------------+-\n",
      "lm_head.layer_norm.bias     | UNEXPECTED | \n",
      "roberta.pooler.dense.bias   | UNEXPECTED | \n",
      "lm_head.bias                | UNEXPECTED | \n",
      "lm_head.dense.weight        | UNEXPECTED | \n",
      "lm_head.dense.bias          | UNEXPECTED | \n",
      "roberta.pooler.dense.weight | UNEXPECTED | \n",
      "lm_head.layer_norm.weight   | UNEXPECTED | \n",
      "classifier.out_proj.weight  | MISSING    | \n",
      "classifier.dense.bias       | MISSING    | \n",
      "classifier.out_proj.bias    | MISSING    | \n",
      "classifier.dense.weight     | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = CamembertForSequenceClassification.from_pretrained(\n",
    "    \"camembert-base\",\n",
    "    num_labels=3\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43199d57",
   "metadata": {},
   "source": [
    "# 6. Entraînement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ca17ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 200/200 [05:37<00:00,  1.69s/batch, loss=0.8086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss moyenne : 0.8603854888677597\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 200/200 [05:36<00:00,  1.68s/batch, loss=0.6976]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss moyenne : 0.8105299969017505\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 200/200 [05:36<00:00,  1.68s/batch, loss=1.2006]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss moyenne : 0.7147563222050667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 3\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
    "    total_loss = 0\n",
    "\n",
    "    # Ajouter tqdm ici\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\", unit=\"batch\")\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Afficher la loss en temps réel\n",
    "        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "    print(\"Loss moyenne :\", total_loss / len(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9135e7a",
   "metadata": {},
   "source": [
    "\n",
    "# 7. Évaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e3c2fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Résultats :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     negatif       0.56      0.52      0.54        95\n",
      "      neutre       0.00      0.00      0.00        41\n",
      "     positif       0.76      0.90      0.82       264\n",
      "\n",
      "    accuracy                           0.72       400\n",
      "   macro avg       0.44      0.47      0.45       400\n",
      "weighted avg       0.64      0.72      0.67       400\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flocon\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\flocon\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\flocon\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "print(\"\\nRésultats :\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    predictions,\n",
    "    target_names=[\"negatif\", \"neutre\", \"positif\"]\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a46bd7",
   "metadata": {},
   "source": [
    "# 8. Test manuel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca8c5c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test manuel :\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m reverse_map[prediction]\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTest manuel :\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpredict_mood\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mJe suis un nigger\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(predict_mood(\u001b[33m\"\u001b[39m\u001b[33mCette journée est incroyable\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(predict_mood(\u001b[33m\"\u001b[39m\u001b[33mLe train arrive à 8h\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mpredict_mood\u001b[39m\u001b[34m(text)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict_mood\u001b[39m(text):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     encoding = \u001b[43mtokenizer\u001b[49m(\n\u001b[32m      3\u001b[39m         text,\n\u001b[32m      4\u001b[39m         return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m         truncation=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      6\u001b[39m         padding=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      7\u001b[39m         max_length=\u001b[32m128\u001b[39m\n\u001b[32m      8\u001b[39m     ).to(device)\n\u001b[32m     10\u001b[39m     outputs = model(**encoding)\n\u001b[32m     11\u001b[39m     prediction = torch.argmax(outputs.logits, dim=\u001b[32m1\u001b[39m).item()\n",
      "\u001b[31mNameError\u001b[39m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def predict_mood(text):\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=128\n",
    "    ).to(device)\n",
    "\n",
    "    outputs = model(**encoding)\n",
    "    prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "\n",
    "    reverse_map = {0: \"negatif\", 1: \"neutre\", 2: \"positif\"}\n",
    "    return reverse_map[prediction]\n",
    "\n",
    "print(\"\\nTest manuel :\")\n",
    "print(predict_mood(\"Je suis un nigger\"))\n",
    "print(predict_mood(\"Cette journée est incroyable\"))\n",
    "print(predict_mood(\"Le train arrive à 8h\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

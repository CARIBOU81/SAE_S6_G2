{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "443f6e4d",
   "metadata": {},
   "source": [
    "# IA prediction d'humeur BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af1403b",
   "metadata": {},
   "source": [
    "instalation des transdormers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1da6a222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: C:\\Users\\flocon\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dotenv in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.9.9)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dotenv) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: C:\\Users\\flocon\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.20.0-cp311-cp311-win_amd64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.7.2)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.4.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.12.19-py2.py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.7.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Using cached protobuf-6.33.5-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: setuptools in c:\\program files\\windowsapps\\pythonsoftwarefoundation.python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\lib\\site-packages (from tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (4.15.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-2.1.1-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.78.1-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Using cached keras-3.13.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorflow) (2.3.4)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Using cached h5py-3.15.1-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.4-cp311-cp311-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached charset_normalizer-3.4.4-cp311-cp311-win_amd64.whl.metadata (38 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow)\n",
      "  Using cached urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2.21.0->tensorflow) (2026.1.4)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached markdown-3.10.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pillow in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Using cached werkzeug-3.1.6-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.6.0)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Using cached wheel-0.46.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow)\n",
      "  Using cached rich-14.3.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Using cached namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Using cached optree-0.18.0-cp311-cp311-win_amd64.whl.metadata (35 kB)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\flocon\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached tensorflow-2.20.0-cp311-cp311-win_amd64.whl (331.8 MB)\n",
      "Using cached grpcio-1.78.1-cp311-cp311-win_amd64.whl (4.8 MB)\n",
      "Using cached ml_dtypes-0.5.4-cp311-cp311-win_amd64.whl (210 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp311-cp311-win_amd64.whl (106 kB)\n",
      "Using cached tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Using cached absl_py-2.4.0-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached wheel-0.46.3-py3-none-any.whl (30 kB)\n",
      "Using cached flatbuffers-25.12.19-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.7.0-py3-none-any.whl (22 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached h5py-3.15.1-cp311-cp311-win_amd64.whl (2.9 MB)\n",
      "Using cached keras-3.13.2-py3-none-any.whl (1.5 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Using cached markdown-3.10.2-py3-none-any.whl (108 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached protobuf-6.33.5-cp310-abi3-win_amd64.whl (437 kB)\n",
      "Using cached termcolor-3.3.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached werkzeug-3.1.6-py3-none-any.whl (225 kB)\n",
      "Using cached wrapt-2.1.1-cp311-cp311-win_amd64.whl (60 kB)\n",
      "Using cached namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached optree-0.18.0-cp311-cp311-win_amd64.whl (312 kB)\n",
      "Using cached rich-14.3.3-py3-none-any.whl (310 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, urllib3, termcolor, tensorboard-data-server, protobuf, optree, opt_einsum, ml_dtypes, mdurl, markdown, h5py, grpcio, google_pasta, gast, charset_normalizer, absl-py, tensorboard, requests, markdown-it-py, astunparse, rich, keras, tensorflow\n",
      "\n",
      "   - --------------------------------------  1/28 [libclang]\n",
      "   - --------------------------------------  1/28 [libclang]\n",
      "   -- -------------------------------------  2/28 [flatbuffers]\n",
      "   ----- ----------------------------------  4/28 [wheel]\n",
      "   ----- ----------------------------------  4/28 [wheel]\n",
      "   ------- --------------------------------  5/28 [werkzeug]\n",
      "   ------- --------------------------------  5/28 [werkzeug]\n",
      "   ------- --------------------------------  5/28 [werkzeug]\n",
      "   ------- --------------------------------  5/28 [werkzeug]\n",
      "   ------- --------------------------------  5/28 [werkzeug]\n",
      "   -------- -------------------------------  6/28 [urllib3]\n",
      "   -------- -------------------------------  6/28 [urllib3]\n",
      "   -------- -------------------------------  6/28 [urllib3]\n",
      "   ------------ ---------------------------  9/28 [protobuf]\n",
      "   ------------ ---------------------------  9/28 [protobuf]\n",
      "   ------------ ---------------------------  9/28 [protobuf]\n",
      "   ------------ ---------------------------  9/28 [protobuf]\n",
      "   ------------ ---------------------------  9/28 [protobuf]\n",
      "   -------------- ------------------------- 10/28 [optree]\n",
      "   --------------- ------------------------ 11/28 [opt_einsum]\n",
      "   --------------- ------------------------ 11/28 [opt_einsum]\n",
      "   ------------------ --------------------- 13/28 [mdurl]\n",
      "   -------------------- ------------------- 14/28 [markdown]\n",
      "   -------------------- ------------------- 14/28 [markdown]\n",
      "   -------------------- ------------------- 14/28 [markdown]\n",
      "   --------------------- ------------------ 15/28 [h5py]\n",
      "   --------------------- ------------------ 15/28 [h5py]\n",
      "   --------------------- ------------------ 15/28 [h5py]\n",
      "   --------------------- ------------------ 15/28 [h5py]\n",
      "   --------------------- ------------------ 15/28 [h5py]\n",
      "   ---------------------- ----------------- 16/28 [grpcio]\n",
      "   ---------------------- ----------------- 16/28 [grpcio]\n",
      "   ---------------------- ----------------- 16/28 [grpcio]\n",
      "   ------------------------ --------------- 17/28 [google_pasta]\n",
      "   ------------------------ --------------- 17/28 [google_pasta]\n",
      "   ------------------------- -------------- 18/28 [gast]\n",
      "   --------------------------- ------------ 19/28 [charset_normalizer]\n",
      "   ---------------------------- ----------- 20/28 [absl-py]\n",
      "   ---------------------------- ----------- 20/28 [absl-py]\n",
      "   ------------------------------ --------- 21/28 [tensorboard]\n",
      "   ------------------------------ --------- 21/28 [tensorboard]\n",
      "   ------------------------------ --------- 21/28 [tensorboard]\n",
      "   ------------------------------ --------- 21/28 [tensorboard]\n",
      "   ------------------------------ --------- 21/28 [tensorboard]\n",
      "   ------------------------------ --------- 21/28 [tensorboard]\n",
      "   ------------------------------ --------- 21/28 [tensorboard]\n",
      "   ------------------------------ --------- 21/28 [tensorboard]\n",
      "   ------------------------------ --------- 21/28 [tensorboard]\n",
      "   ------------------------------ --------- 21/28 [tensorboard]\n",
      "   ------------------------------ --------- 21/28 [tensorboard]\n",
      "   ------------------------------ --------- 21/28 [tensorboard]\n",
      "   ------------------------------ --------- 21/28 [tensorboard]\n",
      "   ------------------------------ --------- 21/28 [tensorboard]\n",
      "   ------------------------------ --------- 21/28 [tensorboard]\n",
      "   ------------------------------ --------- 21/28 [tensorboard]\n",
      "   ------------------------------ --------- 21/28 [tensorboard]\n",
      "   ------------------------------ --------- 21/28 [tensorboard]\n",
      "   ------------------------------ --------- 21/28 [tensorboard]\n",
      "   ------------------------------ --------- 21/28 [tensorboard]\n",
      "   ------------------------------ --------- 21/28 [tensorboard]\n",
      "   ------------------------------- -------- 22/28 [requests]\n",
      "   -------------------------------- ------- 23/28 [markdown-it-py]\n",
      "   -------------------------------- ------- 23/28 [markdown-it-py]\n",
      "   -------------------------------- ------- 23/28 [markdown-it-py]\n",
      "   -------------------------------- ------- 23/28 [markdown-it-py]\n",
      "   -------------------------------- ------- 23/28 [markdown-it-py]\n",
      "   ----------------------------------- ---- 25/28 [rich]\n",
      "   ----------------------------------- ---- 25/28 [rich]\n",
      "   ----------------------------------- ---- 25/28 [rich]\n",
      "   ----------------------------------- ---- 25/28 [rich]\n",
      "   ----------------------------------- ---- 25/28 [rich]\n",
      "   ----------------------------------- ---- 25/28 [rich]\n",
      "   ----------------------------------- ---- 25/28 [rich]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   ------------------------------------- -- 26/28 [keras]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   -------------------------------------- - 27/28 [tensorflow]\n",
      "   ---------------------------------------- 28/28 [tensorflow]\n",
      "\n",
      "Successfully installed absl-py-2.4.0 astunparse-1.6.3 charset_normalizer-3.4.4 flatbuffers-25.12.19 gast-0.7.0 google_pasta-0.2.0 grpcio-1.78.1 h5py-3.15.1 keras-3.13.2 libclang-18.1.1 markdown-3.10.2 markdown-it-py-4.0.0 mdurl-0.1.2 ml_dtypes-0.5.4 namex-0.1.0 opt_einsum-3.4.0 optree-0.18.0 protobuf-6.33.5 requests-2.32.5 rich-14.3.3 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.3.0 urllib3-2.6.3 werkzeug-3.1.6 wheel-0.46.3 wrapt-2.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: C:\\Users\\flocon\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install scikit-learn\n",
    "%pip install dotenv\n",
    "\n",
    "%pip install tensorflow scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f63d4c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a9292c",
   "metadata": {},
   "source": [
    "# 1. Charger les données\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd7c1ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Données chargées : 1000000 lignes\n",
      "✓ Colonnes : ['review_id', 'user_id', 'business_id', 'stars', 'useful', 'funny', 'cool', 'text', 'date']\n",
      "                review_id                 user_id             business_id  \\\n",
      "0  J5Q1gH4ACCj6CtQG7Yom7g  56gL9KEJNHiSDUoyjk2o3Q  8yR12PNSMo6FBYx1u5KPlw   \n",
      "1  HlXP79ecTquSVXmjM10QxQ  bAt9OUFX9ZRgGLCXG22UmA  pBNucviUkNsiqhJv5IFpjg   \n",
      "2  JBBULrjyGx6vHto2osk_CQ  NRHPcLq2vGWqgqwVugSgnQ  8sf9kv6O4GgEb0j1o22N1g   \n",
      "3  U9-43s8YUl6GWBFCpxUGEw  PAxc0qpqt5c2kA0rjDFFAg  XwepyB7KjJ-XGJf0vKc6Vg   \n",
      "4  8T8EGa_4Cj12M6w8vRgUsQ  BqPR1Dp5Rb_QYs9_fz9RiA  prm5wvpp0OHJBlrvTj9uOg   \n",
      "\n",
      "   stars  useful  funny  cool  \\\n",
      "0      2       1      0     0   \n",
      "1      5       0      0     0   \n",
      "2      5       0      0     0   \n",
      "3      4       0      0     0   \n",
      "4      5       0      0     0   \n",
      "\n",
      "                                                text                date  \n",
      "0  Went for lunch and found that my burger was me... 2018-04-04 21:09:53  \n",
      "1  I needed a new tires for my wife's car. They h... 2020-05-24 12:22:14  \n",
      "2  Jim Woltman who works at Goleta Honda is 5 sta... 2019-02-14 03:47:48  \n",
      "3  Been here a few times to get some shrimp.  The... 2013-04-27 01:55:49  \n",
      "4  This is one fantastic place to eat whether you... 2019-05-15 18:29:25  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "FICHIER_REVIEWS = os.getenv(\"INPUT_REVIEWS\")\n",
    "\n",
    "\n",
    "# Méthode 1 : Avec pandas (recommandé)\n",
    "try:\n",
    "    data = pd.read_json(FICHIER_REVIEWS, lines=True)\n",
    "    print(f\"✓ Données chargées : {len(data)} lignes\")\n",
    "    print(f\"✓ Colonnes : {list(data.columns)}\")\n",
    "    print(data.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"✗ Fichier introuvable : {FICHIER_REVIEWS}\")\n",
    "    print(\"Vérifiez que le fichier existe dans le dossier 'data' du répertoire parent\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Erreur : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42093872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def load_yelp_dataset(path):\n",
    "    \"\"\"\n",
    "    Charge le dataset Yelp depuis un fichier JSONL\n",
    "    \"\"\"\n",
    "    # Charger directement avec pandas (beaucoup plus simple et rapide)\n",
    "    data = pd.read_json(path, lines=True)\n",
    "    \n",
    "    # Ne garder que les colonnes nécessaires\n",
    "    df = pd.DataFrame({\n",
    "        \"texte\": data[\"text\"],\n",
    "        \"stars\": data[\"stars\"]\n",
    "    })\n",
    "    \n",
    "    print(f\"✓ Données chargées : {len(df)} lignes\")\n",
    "    print(f\"✓ Distribution des étoiles :\")\n",
    "    print(df[\"stars\"].value_counts().sort_index())\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c952244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Données chargées : 1000000 lignes\n",
      "✓ Distribution des étoiles :\n",
      "stars\n",
      "1    153057\n",
      "2     77630\n",
      "3     98714\n",
      "4    207953\n",
      "5    462646\n",
      "Name: count, dtype: int64\n",
      "1000000\n",
      "                                               texte  stars\n",
      "0  Went for lunch and found that my burger was me...      2\n",
      "1  I needed a new tires for my wife's car. They h...      5\n",
      "2  Jim Woltman who works at Goleta Honda is 5 sta...      5\n",
      "3  Been here a few times to get some shrimp.  The...      4\n",
      "4  This is one fantastic place to eat whether you...      5\n"
     ]
    }
   ],
   "source": [
    "df = load_yelp_dataset(FICHIER_REVIEWS)\n",
    "print(len(df))\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d48ea19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(200000, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0fa8a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stars_to_label(stars):\n",
    "    if stars <= 2:\n",
    "        return 0   # negatif\n",
    "    elif stars == 3:\n",
    "        return 1   # neutre\n",
    "    else:\n",
    "        return 2   # positif\n",
    "\n",
    "df[\"label\"] = df[\"stars\"].apply(stars_to_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaca1fb6",
   "metadata": {},
   "source": [
    "# 2. Train / Test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eedbb83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"texte\"].tolist(),\n",
    "    df[\"label\"].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cbec0c",
   "metadata": {},
   "source": [
    "# 3. Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dff4300",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 10000\n",
    "MAX_LEN = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "#Conversion texte → séquences\n",
    "X_train = tokenizer.texts_to_sequences(train_texts)\n",
    "X_test = tokenizer.texts_to_sequences(test_texts)\n",
    "\n",
    "#padding\n",
    "X_train = pad_sequences(X_train, maxlen=MAX_LEN)\n",
    "X_test = pad_sequences(X_test, maxlen=MAX_LEN)\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce8c43",
   "metadata": {},
   "source": [
    "# 4. Modèle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f4d7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flocon\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\embedding.py:100: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "#LSTM\n",
    "model = Sequential([\n",
    "    Embedding(MAX_WORDS, 128, input_length=MAX_LEN), #vecteur\n",
    "    LSTM(64),\n",
    "    Dense(3, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43199d57",
   "metadata": {},
   "source": [
    "# 6. Entraînement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9ca17ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m4500/4500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 19ms/step - accuracy: 0.8498 - loss: 0.3985 - val_accuracy: 0.8656 - val_loss: 0.3501\n",
      "Epoch 2/5\n",
      "\u001b[1m4500/4500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 20ms/step - accuracy: 0.8821 - loss: 0.3057 - val_accuracy: 0.8738 - val_loss: 0.3227\n",
      "Epoch 3/5\n",
      "\u001b[1m4500/4500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 19ms/step - accuracy: 0.9007 - loss: 0.2568 - val_accuracy: 0.8769 - val_loss: 0.3277\n",
      "Epoch 4/5\n",
      "\u001b[1m4500/4500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 20ms/step - accuracy: 0.9180 - loss: 0.2142 - val_accuracy: 0.8733 - val_loss: 0.3599\n",
      "Epoch 5/5\n",
      "\u001b[1m4500/4500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 19ms/step - accuracy: 0.9341 - loss: 0.1739 - val_accuracy: 0.8720 - val_loss: 0.4047\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9135e7a",
   "metadata": {},
   "source": [
    "\n",
    "# 7. Évaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e3c2fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.8682 - loss: 0.4113\n",
      "Accuracy : 0.8682249784469604\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy :\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a46bd7",
   "metadata": {},
   "source": [
    "# 8. Test manuel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca8c5c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mood(text):\n",
    "\n",
    "    seq = tokenizer.texts_to_sequences([text])\n",
    "    padded = pad_sequences(seq, maxlen=MAX_LEN)\n",
    "\n",
    "    pred = model.predict(padded)\n",
    "    label = np.argmax(pred)\n",
    "\n",
    "    labels = [\"negatif\", \"neutre\", \"positif\"]\n",
    "\n",
    "    return labels[label]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "754fbeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "positif\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "negatif\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "neutre\n"
     ]
    }
   ],
   "source": [
    "print (predict_mood(\"I love this restaurant\"))\n",
    "\n",
    "print (predict_mood(\"This is terrible\"))\n",
    "\n",
    "print (predict_mood(\"It is ok\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
